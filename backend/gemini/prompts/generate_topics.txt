I have provided a list of titles and abstracts from academic papers. Using the information contained in the titles/abstracts, you should categorize them into topics, which are nouns between 1-3 words summarizing the content of the abstract. Each topic can have multiple abstracts, and each abstract can belong to multiple topics. In total, if there are n abstracts, you must not generate more than 3n distinct topics. The topics should be specific and academic, covering specific concepts instead of general domains e.g. "Large Language Models" instead of "Artificial Intelligence". Make the topics as distinct as possible from one another. Refer to the following example for the output format (a json array of topic objects). The output id field refers to the name of the topic. Note: you should not output anything other than the json array. Failure to comply will result in termination.

Input:
[
  {
    "id": "paper_1",
    "title": "Out of One, Many: Using Language Models to Simulate Human Samples",
    "abstract": "We propose and explore the possibility that language models can be studied as effective proxies for specific human subpopulations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the \u201calgorithmic bias\u201d within one such tool\u2014the GPT-3 language model\u2014is instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property algorithmic fidelity and explore its extent in GPT-3. We create \u201csilicon samples\u201d by conditioning the model on thousands of sociodemographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines.",
  },
  {
    "id": "paper_2",
    "title": ""Using cognitive psychology to understand GPT-3",
    "abstract": "Language models are trained to predict the next word for a given text. Recently, it has been shown that scaling up these models causes them to not only generate language but also to solve challenging reasoning problems. The present article lets a large language model (GPT-3) do experiments from the cognitive psychology literature. We find that GPT-3 can solve many of these tasks reasonably well, despite being only taught to predict future word occurrences on a vast amount of text from the Internet and books. We additionally utilize analysis tools from the cognitive psychology literature to demystify how GPT-3 solves different tasks and use the thereby acquired insights to make recommendations for how to improve future model iterations."
  }
]

Output:
[
  {
    "id": "Large Language Models",
    "paper_ids": ["paper_1", "paper_2"]
  },
  {
    "id": "GPT3",
    "paper_ids": ["paper_1", "paper_2"]
  },
  {
    "id": "Cognitive Psychology",
    "paper_ids": ["paper_2"]
  },
  {
    "id": "Societal Simulation",
    "paper_ids": ["paper_1"]
  }
]
