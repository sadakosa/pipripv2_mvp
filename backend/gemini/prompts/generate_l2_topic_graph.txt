You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph. I have provided a list of titles and abstracts from academic papers in the above input. In step 1, using the information contained in the titles/abstracts, you should categorize them into topics, which are nouns between 1-3 words summarizing the content of the abstract. Each topic can have multiple abstracts, and each abstract can belong to multiple topics. In total, if there are n abstracts, you should generate between n/2 and 3n distinct topics. The topics should be specific and academic, covering specific concepts instead of general domains e.g. "Large Language Models" instead of "Artificial Intelligence". Make the topics as distinct as possible from one another. The output should be an array of topic objects in the json field "topics". The output id field refers to the name of the topic. Note: you should not output anything other than the json array.

In step 2, you are to generate a graph where the nodes are the topics generated from step 1, and the edges are the relationship between the topics. The edges should be directed and contain a source node and target node. They should also contain a label that describes the relationship in less than 5 words. For example, "Machine Learning" is a branch of "Artificial Intelligence". Thus, the source node would be "Machine Learning", the target node would be "Artificial Intelligence", and the edge label would be "branch of". The output should be the list of edges in the json field "edges". You should refer to the example input and output below, and follow the JSON format. You should not output anything other than the JSON object. Node must only be from the topics generated from step 1. You must use every topic at least once. Adhere to the rules strictly. Non-compliance will result in termination.

Example input =
[
  {
    "id": "paper_1",
    "title": "Out of One, Many: Using Language Models to Simulate Human Samples",
    "abstract": "We propose and explore the possibility that language models can be studied as effective proxies for specific human subpopulations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the \u201calgorithmic bias\u201d within one such tool\u2014the GPT-3 language model\u2014is instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property algorithmic fidelity and explore its extent in GPT-3. We create \u201csilicon samples\u201d by conditioning the model on thousands of sociodemographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines.",
  },
  {
    "id": "paper_2",
    "title": ""Using cognitive psychology to understand GPT-3",
    "abstract": "Language models are trained to predict the next word for a given text. Recently, it has been shown that scaling up these models causes them to not only generate language but also to solve challenging reasoning problems. The present article lets a large language model (GPT-3) do experiments from the cognitive psychology literature. We find that GPT-3 can solve many of these tasks reasonably well, despite being only taught to predict future word occurrences on a vast amount of text from the Internet and books. We additionally utilize analysis tools from the cognitive psychology literature to demystify how GPT-3 solves different tasks and use the thereby acquired insights to make recommendations for how to improve future model iterations."
  }
]

Example output = {
  "topics": [
    {
      "id": "Large Language Models",
      "paper_ids": ["paper_1", "paper_2"]
    },
    {
      "id": "GPT3",
      "paper_ids": ["paper_1", "paper_2"]
    },
    {
      "id": "Cognitive Psychology",
      "paper_ids": ["paper_2"]
    },
    {
      "id": "Societal Simulation",
      "paper_ids": ["paper_1"]
    }
  ],
  "edges": [
    {
      "source": "GPT3",
      "target": "Large Language Models",
      "label": "type of"
    },
    {
      "source": "Societal Simulation",
      "target": "Cognitive Psychology",
      "label": "technique in"
    }
  ]
}

